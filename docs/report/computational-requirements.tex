To reproduce the results reported in the GAT paper, we ran the GAT model using
PyTorch version 1.9.0~\cite{paszke2019pytorch} on two local machines, a Macbook
and a Dell laptop running Solus OS (a Linux distribution), both of which have
Intel Core i7 CPUs (2.6 GHz on the Macbook, 1.8 GHz on the Dell machine), 16GB
RAM, and Intel UHD GPUs.

On the local systems, we installed PyTorch and all necessary dependencies using
the pip package manager. Training and evaluating the GAT model on the Cora and
Citeseer datasets took approximately 20-25 seconds for 200 epochs. Training and
evaluating the GAT model on the Pubmed dataset took approximately 2 and half
minutes for 200 training epochs.

We tried to run the PPI dataset on both the local machines mentioned earlier.
The Mac system errored out with ``no application memory available''. The Linux
ran for roughly 16 hours before completing. We ended up only running a single
model once on the PPI data and we ended up discarding our results because the
architecture didn't quite match what was used in the paper.

Overall, the computational requirements for reproducing the GAT results on a
local system are high for the PPI data and low for the other datasets, and may
require a GPU for faster training times, which is especially important for the
PPI dataset.
