To reproduce the results reported in the GAT paper, we implemented the GAT model using PyTorch version 1.9.0~\cite{paszke2019pytorch} on three platforms:
\begin{itemize}
    \item two local systems, a macbook and a Windows both with an Intel Core i7 CPU (2.6 GHz and 1.8 GHz), 16GB RAM,
    and Intel UHD GPU;
    \item Google Colab's free GPU instance with 12GB of RAM\@.
\end{itemize}

On the local system, we installed PyTorch and all necessary dependencies using the pip package manager.
Training and evaluating the GAT model on the Cora and Citeseer datasets took approximately 20-25 seconds per 200 epochs.

We installed PyTorch and all necessary dependencies within the notebook.
We also used Google's free Compute instance with 12GB of RAM, which allowed us to train the GAT model on larger
datasets such as Pubmed and PPI\@.
Training the GAT model on the Pubmed dataset took approximately 20 seconds per 200 epochs, while training on the PPI
dataset took approximately 30 minutes per epoch which is also not consistent due to large memory requirement.

Overall, the computational requirements for reproducing the GAT results on a local system are moderate, but may require a GPU for faster training times.
