To reproduce the results reported in the GAT paper, we ran the GAT model using
PyTorch version 1.9.0~\cite{paszke2019pytorch} on two local machines, a Macbook
and Dell laptop running Solus OS (a Linux distribution), both of which have
Intel Core i7 CPUs (2.6 GHz on the Macbook, 1.8 GHz on the Dell machine), 16GB
RAM, and Intel UHD GPUs.

On the local systems, we installed PyTorch and all necessary dependencies using
the pip package manager. Training and evaluating the GAT model on the Cora and
Citeseer datasets took approximately 20-25 seconds per 200 epochs. Training and
evaluating the GAT model on the Pubmed dataset took approximately 2 and half
minutes with 200 training epochs. Training and evaluating the GAT model on the
PPI dataset took sufficiently long that we only ran it once to completion and
at this point had not yet implemented a timing mechanism in our code. The PPI
training ran for approximately two entire work days, so roughly 16 hours.

Overall, the computational requirements for reproducing the GAT results on a
local system are moderate, but may require a GPU for faster training times,
which is especially important for the PPI dataset.
