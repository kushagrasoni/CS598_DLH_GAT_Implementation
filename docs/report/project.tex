\documentclass{article}
\usepackage{minted}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{float}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{microtype}
\usepackage[hyperref]{project}
\usepackage{pythonhighlight}
\usepackage{booktabs,chemformula}
\renewcommand{\UrlFont}{\ttfamily\small}

\aclfinalcopy


\newcommand\BibTeX{B\textsc{ib}\TeX}

\title{Project Draft: Reproduce and Experiment with Graph Attention Networks}

\author
{Valle-Mena, Ricardo Ruy and Soni, Kushagra \\
    \texttt{\{rrv4, soni14\}@illinois.edu}
    \\[2em]
    Group ID: 179\\
    Paper ID: 7\\
    Code link: \url{https://github.com/kushagrasoni/CS598_DLH_GAT_Implementation}
    \\[2em]
}

\begin{document}
    \maketitle

    \section{Introduction}\label{sec:introduction}

    Graph Attention Networks (GATs)~\cite{velickovic2018graph} are a type of neural network architecture designed for
    processing graph-structured data.
    They aim to overcome the limitations of previous architectures by being able to operate on arbitrarily structured graphs in a parallelizable manner.
    GATs use a masked shared self-attention mechanism to assign weights to each node's neighbors and combine their features, resulting in a new set of features for the node in question.
    GATs have shown promising results in various graph-based tasks, including node classification and link prediction.

    \section{Scope of Reproducibility}\label{sec:scope-of-reproducibility}

    \subsection{Background and Problem Statement}\label{sec:background-and-problem-statement}
    \input{background-and-problem-statement}

    \subsection{Objectives}\label{sec:objectives}
    Our goal was to reproduce the results reported in the original paper, which used the Cora, Citeseer, Pubmed, and Protein-protein interaction datasets. Specifically, we aimed for:
    \begin{itemize}
        \item Classification accuracies of approximately 83.0\%, 72.5\%, and 79\% in the Cora, Citeseer, and Pubmed
        datasets, respectively,
        \item Micro-averaged F1 score of approximately 0.973 in the protein-protein interaction dataset.
    \end{itemize}
    We hypothesized that our results would be as good or better than those found in previous studies.

    In all four datasets, the results from the paper found were as good or better as the results found in previous studies.
    Furthermore, we conducted the following ablation studies:
    \begin{itemize}
        \item Using one, two, and three layer models for the Citeseer, Cora, and Pubmed datasets
	\item Not using dropout
	\item Not using L2 regularization
    \end{itemize}

    \section{Methodology}\label{sec:methodology}
    All datasets from the paper are publicly available in multiple locations, including the Pytorch Geometric library. We have been running our experiments locally. Despite the datasets being relatively small, the PPI dataset turned out to be sufficiently large to take a prohibitively long time to run. We therefore do not provide the same amount of results for the PPI dataset as for the other three.

    \subsection{Model Description}\label{subsec:model-description}
    \input{model-description}

    \subsection{Data Description}\label{subsec:data-description}
    \input{data-description}

    \subsection{Model Implementation}\label{subsec:model-implementation}
    \input{model-implementation}

    \subsection{Computational Requirements}\label{subsec:computational-requirements}
    \input{computational-requirements}

    \section{Results}\label{sec:results}
    \input{results}

    \section{Limitations and Challenges}\label{sec:limitations-and-challenges}
    As mentioned previously, the PPI dataset turned out to be sufficiently large to make experimenting with it prohibitively slow, so we were unable to experiment with it as thoroughly as with the other three datasets. We are unsure whether getting our code to run on a GPU would change this.

    \bibliographystyle{unsrt} %Reference style.
    \bibliography{references}

\end{document}

