So far we have only been able to inaccurately replicate the paper's
experiments: as mentioned earlier, the Pytorch Geometric GAT implementation is
not flexible enough to do exactly what the paper does.
Our preliminary results are encouraging however.
Our test accuracy on the Pubmed data is essentially
indistinguishable from the one reported in the paper, and the test accuracy on
the Citeseer and Cora datasets are about 5\% worse than the ones reported in
paper.
Refer below Table~\ref{tab:results-table}.

\begin{table}
    \begin{tabular}{llll}
        \toprule
        \midrule
        \textbf{Dataset} & \textbf{Epochs} & \textbf{Score Type} & \textbf{Results} \\
        \ch{Cora}     & 200    & Accuracy   & 0.82  \\
        \ch{Citeseer} & 200    & Accuracy   & 0.73  \\
        \ch{Pubmed}   & 200    & Accuracy   & 0.79  \\
        \ch{PPI}      & 200    & F1 Score   & 0.369 \\
        \bottomrule
    \end{tabular}
    \caption{Results using torch geometric's GAT library}
    \label{tab:results-table}
\end{table}

We see signs of overfitting in our experiments and believe that reducing the
overfitting will improve our test accuracy further.
Specifically, on the Citeseer, Cora and Pubmed datasets, the training accuracy reaches 100\%.
The paper implements an early stopping mechanism during training, presumably to
avoid this exact problem.
Unfortunately, there are no details about how the mechanism works;
it is described in a single sentence.
We will attempt to implement our own such mechanism and hope it will reduce overfitting and
improve test accuracy.
