{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e88f4d24",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid, PPI\n",
    "from torch_geometric.nn import GAT\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c036f110",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*****************************************************************************************************\n",
      "\n",
      "                                         citeseer() \n",
      "                                         Total Epochs: 200\n",
      "                                         Test Accuracy: 0.6670\n",
      "                                         Time Taken: 0:00:29.233131\n",
      "\n",
      "*****************************************************************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*****************************************************************************************************\n",
      "\n",
      "                                         cora() \n",
      "                                         Total Epochs: 200\n",
      "                                         Test Accuracy: 0.8070\n",
      "                                         Time Taken: 0:00:18.929057\n",
      "\n",
      "*****************************************************************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*****************************************************************************************************\n",
      "\n",
      "                                         pubmed() \n",
      "                                         Total Epochs: 200\n",
      "                                         Test Accuracy: 0.7770\n",
      "                                         Time Taken: 0:01:14.338753\n",
      "\n",
      "*****************************************************************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in ['citeseer', 'cora', 'pubmed']:\n",
    "  start = datetime.now()\n",
    "  dataset = Planetoid(root=f'../data/{dataset}', name=dataset)\n",
    "  # Define model and optimizer\n",
    "  model = GAT(\n",
    "      in_channels=dataset.num_features,\n",
    "      out_channels=dataset.num_classes,\n",
    "      hidden_channels=8,\n",
    "      num_layers=2,\n",
    "      heads=8,\n",
    "      dropout=0.6,\n",
    "      act='elu',\n",
    "      act_first=True\n",
    "  )\n",
    "  # {'PairNorm', 'GraphSizeNorm', 'HeteroLayerNorm', 'InstanceNorm', 'BatchNorm', 'DiffGroupNorm', 'GraphNorm', 'HeteroBatchNorm', 'MessageNorm', 'MeanSubtractionNorm', 'LayerNorm'}\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "\n",
    "  # Train model\n",
    "  for epoch in range(200):\n",
    "      model.train()\n",
    "      optimizer.zero_grad()\n",
    "      out = model(dataset.x, dataset.edge_index)\n",
    "      #loss = F.nll_loss(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "      loss = F.cross_entropy(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # Evaluate model\n",
    "      model.eval()\n",
    "      pred = model(dataset.x, dataset.edge_index).argmax(dim=1)\n",
    "      correct = int(pred[dataset.train_mask].eq(dataset.y[dataset.train_mask]).sum().item())\n",
    "      acc = correct / int(dataset.train_mask.sum())\n",
    "      # print(f'Epoch {epoch + 1:03d}, Loss: {loss:.4f}, Test Acc: {acc:.4f}')\n",
    "\n",
    "\n",
    "  # Test the model\n",
    "  model.eval()\n",
    "  out = model(dataset.x, dataset.edge_index)\n",
    "  pred = out.argmax(dim=1)\n",
    "  acc = pred[dataset.test_mask].eq(dataset.y[dataset.test_mask]).sum().item() / int(dataset.test_mask.sum())\n",
    "  print('\\n\\n*****************************************************************************************************\\n')\n",
    "  print(f'                                         {dataset} ')\n",
    "  print(f'                                         Total Epochs: 200')\n",
    "  print(f'                                         Test Accuracy: {acc:.4f}')\n",
    "  print(f'                                         Time Taken: {datetime.now() - start}')\n",
    "  print('\\n*****************************************************************************************************\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://data.dgl.ai/dataset/ppi.zip\n",
      "Extracting ../data/ppi/ppi.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ppi_train = PPI('../data/ppi/')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model = GAT(\n",
    "    in_channels=ppi_train.num_features,\n",
    "    out_channels=ppi_train.num_classes,\n",
    "    hidden_channels=8,\n",
    "    num_layers=2,\n",
    "    heads=8,\n",
    "    dropout=0.6,\n",
    "    act='elu',\n",
    "    act_first=True\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "# Train model\n",
    "for epoch in range(2):\n",
    "  print(epoch)\n",
    "  model.train()\n",
    "  optimizer.zero_grad()\n",
    "  out = model(ppi_train.x, ppi_train.edge_index)\n",
    "  loss = F.cross_entropy(out, ppi_train.y)\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  # Evaluate model\n",
    "  model.eval()\n",
    "  pred = model(ppi_train.x, ppi_train.edge_index) > .5\n",
    "  f1 = sklearn.metrics.f1_score(ppi_train.y.detach().numpy(), pred.detach().numpy(), average='micro')\n",
    "  #print(f'Epoch {epoch + 1:03d}, Loss: {loss:.4f}, F1: {f1}')\n",
    "\n",
    "\n",
    "# Test the model\n",
    "ppi_test = PPI('../data/ppi/', 'test')\n",
    "model.eval()\n",
    "out = model(ppi_test.x, ppi_test.edge_index) > .5\n",
    "f1 = sklearn.metrics.f1_score(ppi_test.y.detach().numpy(), out.detach().numpy(), average='micro')\n",
    "print('\\n\\n*****************************************************************************************************\\n')\n",
    "print(f'                                         PPI Dataset ')\n",
    "print(f'                                         Total Epochs: 200')\n",
    "print(f'                                         F1 Score: {f1:.4f}')\n",
    "print(f'                                         Time Taken: {datetime.now() - start}')\n",
    "print('\\n*****************************************************************************************************\\n\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}