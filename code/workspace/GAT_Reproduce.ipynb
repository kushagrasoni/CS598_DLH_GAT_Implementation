{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e88f4d24",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid, PPI\n",
    "from torch_geometric.nn import GAT\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c036f110",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*****************************************************************************************************\n",
      "\n",
      "                                         citeseer() \n",
      "                                         Total Epochs: 200\n",
      "                                         Test Accuracy: 0.6730\n",
      "                                         Time Taken: 0:00:17.812977\n",
      "\n",
      "*****************************************************************************************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*****************************************************************************************************\n",
      "\n",
      "                                         cora() \n",
      "                                         Total Epochs: 200\n",
      "                                         Test Accuracy: 0.8050\n",
      "                                         Time Taken: 0:00:11.101380\n",
      "\n",
      "*****************************************************************************************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*****************************************************************************************************\n",
      "\n",
      "                                         pubmed() \n",
      "                                         Total Epochs: 200\n",
      "                                         Test Accuracy: 0.7780\n",
      "                                         Time Taken: 0:01:03.165607\n",
      "\n",
      "*****************************************************************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in ['citeseer', 'cora', 'pubmed']:\n",
    "  start = datetime.now()\n",
    "  dataset = Planetoid(root=f'../data/{dataset}', name=dataset)\n",
    "  # Define model and optimizer\n",
    "  model = GAT(\n",
    "      in_channels=dataset.num_features,\n",
    "      out_channels=dataset.num_classes,\n",
    "      hidden_channels=8,\n",
    "      num_layers=2,\n",
    "      heads=8,\n",
    "      dropout=0.6,\n",
    "      act='elu',\n",
    "      act_first=True\n",
    "  )\n",
    "  # {'PairNorm', 'GraphSizeNorm', 'HeteroLayerNorm', 'InstanceNorm', 'BatchNorm', 'DiffGroupNorm', 'GraphNorm', 'HeteroBatchNorm', 'MessageNorm', 'MeanSubtractionNorm', 'LayerNorm'}\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "\n",
    "  # Train model\n",
    "  for epoch in range(200):\n",
    "      model.train()\n",
    "      optimizer.zero_grad()\n",
    "      out = model(dataset.x, dataset.edge_index)\n",
    "      #loss = F.nll_loss(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "      loss = F.cross_entropy(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # Evaluate model\n",
    "      model.eval()\n",
    "      pred = model(dataset.x, dataset.edge_index).argmax(dim=1)\n",
    "      correct = int(pred[dataset.train_mask].eq(dataset.y[dataset.train_mask]).sum().item())\n",
    "      acc = correct / int(dataset.train_mask.sum())\n",
    "      # print(f'Epoch {epoch + 1:03d}, Loss: {loss:.4f}, Test Acc: {acc:.4f}')\n",
    "\n",
    "\n",
    "  # Test the model\n",
    "  model.eval()\n",
    "  out = model(dataset.x, dataset.edge_index)\n",
    "  pred = out.argmax(dim=1)\n",
    "  acc = pred[dataset.test_mask].eq(dataset.y[dataset.test_mask]).sum().item() / int(dataset.test_mask.sum())\n",
    "  print('\\n\\n*****************************************************************************************************\\n')\n",
    "  print(f'                                         {dataset} ')\n",
    "  print(f'                                         Total Epochs: 200')\n",
    "  print(f'                                         Test Accuracy: {acc:.4f}')\n",
    "  print(f'                                         Time Taken: {datetime.now() - start}')\n",
    "  print('\\n*****************************************************************************************************\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23753bdc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://data.dgl.ai/dataset/ppi.zip\n",
      "Extracting ../data/ppi/ppi.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ppi_train = PPI('../data/ppi/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea5eab77",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = GAT(\n",
    "    in_channels=ppi_train.num_features,\n",
    "    out_channels=ppi_train.num_classes,\n",
    "    hidden_channels=256,\n",
    "    num_layers=3,\n",
    "    heads=4,\n",
    "    dropout=0.6,\n",
    "    act='elu',\n",
    "    act_first=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52f1478d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f038ae",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "# Train model\n",
    "for epoch in range(2):\n",
    "  print(epoch)\n",
    "  model.train()\n",
    "  optimizer.zero_grad()\n",
    "  out = model(ppi_train.x, ppi_train.edge_index)\n",
    "  loss = F.cross_entropy(out, ppi_train.y)\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  # Evaluate model\n",
    "  model.eval()\n",
    "  pred = model(ppi_train.x, ppi_train.edge_index) > .5\n",
    "  f1 = sklearn.metrics.f1_score(ppi_train.y.detach().numpy(), pred.detach().numpy(), average='micro')\n",
    "  #print(f'Epoch {epoch + 1:03d}, Loss: {loss:.4f}, F1: {f1}')\n",
    "\n",
    "\n",
    "# Test the model\n",
    "ppi_test = PPI('../data/ppi/', 'test')\n",
    "model.eval()\n",
    "out = model(ppi_test.x, ppi_test.edge_index) > .5\n",
    "f1 = sklearn.metrics.f1_score(ppi_test.y.detach().numpy(), out.detach().numpy(), average='micro')\n",
    "print('\\n\\n*****************************************************************************************************\\n')\n",
    "print(f'                                         PPI Dataset ')\n",
    "print(f'                                         Total Epochs: 200')\n",
    "print(f'                                         F1 Score: {f1:.4f}')\n",
    "print(f'                                         Time Taken: {datetime.now() - start}')\n",
    "print('\\n*****************************************************************************************************\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alright, now to implement our own version of GAT to more closely follow the paper. Specifically, this is an attempt at reproducing the model they used for the Cora and Citeseer datasets. The Pubmed model is slightly different, and the PPI model is significantly different.\n",
    "\n",
    "It is unclear from the description in the paper whether GATConv applies dropout in the same way as the paper describes. If we have time, we'll have to revisit the original GAT implementation and compare their dropout methodology with that implemented by GATConv. If they are not the same and if there is time, we will have to go one level lower, either implementing our own GATConv (perhaps forking the one in pytorch geometric?), or implementing our own GAT from scratch.\n",
    "\n",
    "Furthermore, the paper talks about applying L2 regularization, which we are not doing, and which GATConv does not appear to provide an option for. One step at a time though..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "class GATCora(torch.nn.Module):\n",
    "  def __init__(self, in_channels, n_classes):\n",
    "    super().__init__()\n",
    "    self.conv1 = torch_geometric.nn.GATConv(heads=8, out_channels=8, in_channels=in_channels, dropout=.6)\n",
    "    self.act1 = torch.nn.ELU()\n",
    "    self.conv2 = torch_geometric.nn.GATConv(heads=1, out_channels=n_classes, in_channels=64, dopout=.6)\n",
    "    self.act2 = torch.nn.Softmax(dim=1)\n",
    "\n",
    "  def forward(self, x, edge_index):\n",
    "    x = self.act1(self.conv1(x, edge_index))\n",
    "    x = self.act2(self.conv2(x, edge_index))\n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*****************************************************************************************************\n",
      "\n",
      "                                         citeseer() \n",
      "                                         Total Epochs: 200\n",
      "                                         Test Accuracy: 0.6720\n",
      "                                         Time Taken: 0:00:42.444737\n",
      "\n",
      "*****************************************************************************************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*****************************************************************************************************\n",
      "\n",
      "                                         cora() \n",
      "                                         Total Epochs: 200\n",
      "                                         Test Accuracy: 0.7880\n",
      "                                         Time Taken: 0:00:20.017430\n",
      "\n",
      "*****************************************************************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in ['citeseer', 'cora']:\n",
    "  start = datetime.now()\n",
    "  dataset = Planetoid(root=f'../data/{dataset}', name=dataset)\n",
    "  # Define model and optimizer\n",
    "  model = GATCora(dataset.num_features, dataset.num_classes)\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "\n",
    "  # Train model\n",
    "  for epoch in range(200):\n",
    "      model.train()\n",
    "      optimizer.zero_grad()\n",
    "      out = model(dataset.x, dataset.edge_index)\n",
    "      #loss = F.nll_loss(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "      loss = F.cross_entropy(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # Evaluate model\n",
    "      model.eval()\n",
    "      pred = model(dataset.x, dataset.edge_index).argmax(dim=1)\n",
    "      correct = int(pred[dataset.train_mask].eq(dataset.y[dataset.train_mask]).sum().item())\n",
    "      acc = correct / int(dataset.train_mask.sum())\n",
    "#       print(f'Epoch {epoch + 1:03d}, Loss: {loss:.4f}, Test Acc: {acc:.4f}')\n",
    "\n",
    "\n",
    "  # Test the model\n",
    "  model.eval()\n",
    "  out = model(dataset.x, dataset.edge_index)\n",
    "  pred = out.argmax(dim=1)\n",
    "  acc = pred[dataset.test_mask].eq(dataset.y[dataset.test_mask]).sum().item() / int(dataset.test_mask.sum())\n",
    "  print('\\n\\n*****************************************************************************************************\\n')\n",
    "  print(f'                                         {dataset} ')\n",
    "  print(f'                                         Total Epochs: 200')\n",
    "  print(f'                                         Test Accuracy: {acc:.4f}')\n",
    "  print(f'                                         Time Taken: {datetime.now() - start}')\n",
    "  print('\\n*****************************************************************************************************\\n\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class GATPubmed(torch.nn.Module):\n",
    "  def __init__(self, in_channels, n_classes):\n",
    "    super().__init__()\n",
    "    self.conv1 = torch_geometric.nn.GATConv(heads=8, out_channels=8, in_channels=in_channels, dropout=.6)\n",
    "    self.act1 = torch.nn.ELU()\n",
    "    self.conv2 = torch_geometric.nn.GATConv(heads=8, out_channels=n_classes, in_channels=64, dopout=.6, concat=False)\n",
    "    self.act2 = torch.nn.Softmax(dim=1)\n",
    "\n",
    "  def forward(self, x, edge_index):\n",
    "    x = self.act1(self.conv1(x, edge_index))\n",
    "    x = self.act2(self.conv2(x, edge_index))\n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "dataset = Planetoid(root=f'../data/pubmed', name='pubmed')\n",
    "# Define model and optimizer\n",
    "model = GATPubmed(dataset.num_features, dataset.num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "\n",
    "# Train model\n",
    "for epoch in range(200):\n",
    "  model.train()\n",
    "  optimizer.zero_grad()\n",
    "  out = model(dataset.x, dataset.edge_index)\n",
    "  #loss = F.nll_loss(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "  loss = F.cross_entropy(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  # Evaluate model\n",
    "  model.eval()\n",
    "  pred = model(dataset.x, dataset.edge_index).argmax(dim=1)\n",
    "  correct = int(pred[dataset.train_mask].eq(dataset.y[dataset.train_mask]).sum().item())\n",
    "  acc = correct / int(dataset.train_mask.sum())\n",
    "#       print(f'Epoch {epoch + 1:03d}, Loss: {loss:.4f}, Test Acc: {acc:.4f}')\n",
    "\n",
    "\n",
    "# Test the model\n",
    "model.eval()\n",
    "out = model(dataset.x, dataset.edge_index)\n",
    "pred = out.argmax(dim=1)\n",
    "acc = pred[dataset.test_mask].eq(dataset.y[dataset.test_mask]).sum().item() / int(dataset.test_mask.sum())\n",
    "print('\\n\\n*****************************************************************************************************\\n')\n",
    "print(f'                                         Pubmed ')\n",
    "print(f'                                         Total Epochs: 200')\n",
    "print(f'                                         Test Accuracy: {acc:.4f}')\n",
    "print(f'                                         Time Taken: {datetime.now() - start}')\n",
    "print('\\n*****************************************************************************************************\\n\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "97807703",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Alright, now to implement our own version of GAT to more closely follow the paper. Specifically, this is an attempt at reproducing the model they used for the Cora and Citeseer datasets. The Pubmed model is slightly different, and the PPI model is significantly different.\n",
    "\n",
    "It is unclear from the description in the paper whether GATConv applies dropout in the same way as the paper describes. If we have time, we'll have to revisit the original GAT implementation and compare their dropout methodology with that implemented by GATConv. If they are not the same and if there is time, we will have to go one level lower, either implementing our own GATConv (perhaps forking the one in pytorch geometric?), or implementing our own GAT from scratch.\n",
    "\n",
    "Furthermore, the paper talks about applying L2 regularization, which we are not doing, and which GATConv does not appear to provide an option for. One step at a time though..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "317bca1f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from datetime import datetime\n",
    "\n",
    "class GATCora(torch.nn.Module):\n",
    "  def __init__(self, in_channels, n_classes):\n",
    "    super().__init__()\n",
    "    self.conv1 = torch_geometric.nn.GATConv(heads=8, out_channels=8, in_channels=in_channels, dropout=.6)\n",
    "    self.act1 = torch.nn.ELU()\n",
    "    self.conv2 = torch_geometric.nn.GATConv(heads=1, out_channels=n_classes, in_channels=64, dopout=.6)\n",
    "    self.act2 = torch.nn.Softmax(dim=1)\n",
    "\n",
    "  def forward(self, x, edge_index):\n",
    "    x = self.act1(self.conv1(x, edge_index))\n",
    "    x = self.act2(self.conv2(x, edge_index))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ae43436",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*****************************************************************************************************\n",
      "\n",
      "                                         citeseer() \n",
      "                                         Total Epochs: 200\n",
      "                                         Test Accuracy: 0.6900\n",
      "                                         Time Taken: 0:00:40.600561\n",
      "\n",
      "*****************************************************************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*****************************************************************************************************\n",
      "\n",
      "                                         cora() \n",
      "                                         Total Epochs: 200\n",
      "                                         Test Accuracy: 0.7860\n",
      "                                         Time Taken: 0:00:21.043799\n",
      "\n",
      "*****************************************************************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in ['citeseer', 'cora']:\n",
    "  start = datetime.now()\n",
    "  dataset = Planetoid(root=f'../data/{dataset}', name=dataset)\n",
    "  # Define model and optimizer\n",
    "  model = GATCora(dataset.num_features, dataset.num_classes)\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "\n",
    "  # Train model\n",
    "  for epoch in range(200):\n",
    "      model.train()\n",
    "      optimizer.zero_grad()\n",
    "      out = model(dataset.x, dataset.edge_index)\n",
    "      #loss = F.nll_loss(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "      loss = F.cross_entropy(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # Evaluate model\n",
    "      model.eval()\n",
    "      pred = model(dataset.x, dataset.edge_index).argmax(dim=1)\n",
    "      correct = int(pred[dataset.train_mask].eq(dataset.y[dataset.train_mask]).sum().item())\n",
    "      acc = correct / int(dataset.train_mask.sum())\n",
    "#       print(f'Epoch {epoch + 1:03d}, Loss: {loss:.4f}, Test Acc: {acc:.4f}')\n",
    "\n",
    "\n",
    "  # Test the model\n",
    "  model.eval()\n",
    "  out = model(dataset.x, dataset.edge_index)\n",
    "  pred = out.argmax(dim=1)\n",
    "  acc = pred[dataset.test_mask].eq(dataset.y[dataset.test_mask]).sum().item() / int(dataset.test_mask.sum())\n",
    "  print('\\n\\n*****************************************************************************************************\\n')\n",
    "  print(f'                                         {dataset} ')\n",
    "  print(f'                                         Total Epochs: 200')\n",
    "  print(f'                                         Test Accuracy: {acc:.4f}')\n",
    "  print(f'                                         Time Taken: {datetime.now() - start}')\n",
    "  print('\\n*****************************************************************************************************\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26637316",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class GATPubmed(torch.nn.Module):\n",
    "  def __init__(self, in_channels, n_classes):\n",
    "    super().__init__()\n",
    "    self.conv1 = torch_geometric.nn.GATConv(heads=8, out_channels=8, in_channels=in_channels, dropout=.6)\n",
    "    self.act1 = torch.nn.ELU()\n",
    "    self.conv2 = torch_geometric.nn.GATConv(heads=8, out_channels=n_classes, in_channels=64, dopout=.6, concat=False)\n",
    "    self.act2 = torch.nn.Softmax(dim=1)\n",
    "\n",
    "  def forward(self, x, edge_index):\n",
    "    x = self.act1(self.conv1(x, edge_index))\n",
    "    x = self.act2(self.conv2(x, edge_index))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e9cdee7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*****************************************************************************************************\n",
      "\n",
      "                                         Pubmed \n",
      "                                         Total Epochs: 200\n",
      "                                         Test Accuracy: 0.7830\n",
      "                                         Time Taken: 0:01:45.892788\n",
      "\n",
      "*****************************************************************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "dataset = Planetoid(root=f'../data/pubmed', name='pubmed')\n",
    "# Define model and optimizer\n",
    "model = GATPubmed(dataset.num_features, dataset.num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "\n",
    "# Train model\n",
    "for epoch in range(200):\n",
    "  model.train()\n",
    "  optimizer.zero_grad()\n",
    "  out = model(dataset.x, dataset.edge_index)\n",
    "  #loss = F.nll_loss(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "  loss = F.cross_entropy(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  # Evaluate model\n",
    "  model.eval()\n",
    "  pred = model(dataset.x, dataset.edge_index).argmax(dim=1)\n",
    "  correct = int(pred[dataset.train_mask].eq(dataset.y[dataset.train_mask]).sum().item())\n",
    "  acc = correct / int(dataset.train_mask.sum())\n",
    "#       print(f'Epoch {epoch + 1:03d}, Loss: {loss:.4f}, Test Acc: {acc:.4f}')\n",
    "\n",
    "\n",
    "# Test the model\n",
    "model.eval()\n",
    "out = model(dataset.x, dataset.edge_index)\n",
    "pred = out.argmax(dim=1)\n",
    "acc = pred[dataset.test_mask].eq(dataset.y[dataset.test_mask]).sum().item() / int(dataset.test_mask.sum())\n",
    "print('\\n\\n*****************************************************************************************************\\n')\n",
    "print(f'                                         Pubmed ')\n",
    "print(f'                                         Total Epochs: 200')\n",
    "print(f'                                         Test Accuracy: {acc:.4f}')\n",
    "print(f'                                         Time Taken: {datetime.now() - start}')\n",
    "print('\\n*****************************************************************************************************\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a6b1d1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}